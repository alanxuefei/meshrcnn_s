{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import train_net_shapenet\n",
    "\n",
    "class args:\n",
    "    config_file = \"configs/shapenet/voxmesh_R50.yaml\"\n",
    "    opts = \"\"\n",
    "    num_gpus = 0\n",
    "    data_dir = 'ShapeNetV1processed'\n",
    "    copy_data = False\n",
    "    no_color = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = train_net_shapenet.setup(args())\n",
    "loaders = train_net_shapenet.setup_loaders(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def rotateback(voxels, P):\n",
    "    voxel_coords = []\n",
    "    for i, cur_voxels in enumerate(voxels):              \n",
    "        cur_voxel_coords = loaders[\"train\"].dataset._coordinates(cur_voxels, P[i].inverse())\n",
    "        voxel_coords.append(cur_voxel_coords) \n",
    "    voxel_coords = tuple(voxel_coords)\n",
    "    \n",
    "    voxels = []\n",
    "    for i, cur_voxel_coords in enumerate(voxel_coords):\n",
    "        cur_voxels = loaders[\"train\"].dataset._voxelize(cur_voxel_coords, P[0])\n",
    "        voxels.append(cur_voxels)\n",
    "    voxels = torch.stack(voxels, dim=0)\n",
    "    \n",
    "    return voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "for i, batch in enumerate(loaders[\"train\"]):\n",
    "    _, _, _, _, _, Ps, id_strs = batch \n",
    "    batch = loaders[\"train\"].postprocess(batch, 'cpu')\n",
    "    _, _, _, _, voxels_gt = batch\n",
    "    voxels_gt = voxels_gt.float()\n",
    "    #voxels_gt = rotateback(voxels_gt.cpu(), Ps.cpu())\n",
    "    #print(voxels_gt.shape)\n",
    "    \n",
    "    #words = id_strs[0].split('-')\n",
    "    #output_dir = \"/home/alan/Desktop/meshrcnn_s/meshrcnn_s/datasets/shapenet/predictedVoxel\"\n",
    "    #output_dir = os.path.join(output_dir, words[0], words[1], \"predictedVoxels.pt\")\n",
    "    #if not exists(output_dir):\n",
    "    #    missed.append(output_dir)\n",
    "    #    continue\n",
    "    \n",
    "    #voxel_scores = (torch.load(output_dir).sigmoid()>0.7).float()\n",
    "    #print(voxel_scores.shape)    \n",
    "    #voxel_scores = rotateback(voxel_scores.cpu(), Ps.cpu())    \n",
    "\n",
    "    fig = make_subplots(\n",
    "    rows=6, cols=2,\n",
    "    specs=[[{'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}]])    \n",
    "     \n",
    "    for index in range(0, 6):\n",
    " \n",
    "        X, Y, Z = np.mgrid[0:48:48j, 0:48:48j, 0:48:48j]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Volume(\n",
    "                x=X.flatten(),\n",
    "                y=Y.flatten(),\n",
    "                z=Z.flatten(),\n",
    "                value=voxels_gt[index].cpu().detach().numpy().flatten(),\n",
    "                isomin=0,\n",
    "                isomax=1,\n",
    "                opacity=0.1, # needs to be small to see through all surfaces\n",
    "                surface_count=20, # needs to be a large number for good volume rendering\n",
    "                ),\n",
    "            row=index + 1,\n",
    "            col=1,\n",
    "        )   \n",
    "\n",
    "        X, Y, Z = np.mgrid[0:48:48j, 0:48:48j, 0:48:48j]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Volume(\n",
    "                x=X.flatten(),\n",
    "                y=Y.flatten(),\n",
    "                z=Z.flatten(),\n",
    "                value=voxel_scores[index].cpu().detach().numpy().flatten(),\n",
    "                isomin=0,\n",
    "                isomax=1,\n",
    "                opacity=0.1, # needs to be small to see through all surfaces\n",
    "                surface_count=20, # needs to be a large number for good volume rendering\n",
    "                ),\n",
    "            row=index + 1,\n",
    "            col=2,\n",
    "        )\n",
    "        \n",
    "        print(np.histogram(voxels_gt[index].detach().numpy().flatten()))\n",
    "        print(\"voxel_scores\")\n",
    "        print(np.histogram(voxel_scores[index].cpu().detach().numpy().flatten()))\n",
    "        \n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=8000,)\n",
    "        \n",
    "    fig.show()\n",
    "     \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "checkpoint_path = \"/home/alan/Desktop/lstm3dtest/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)\n",
    " \n",
    "for i, batch in enumerate(loaders[\"train\"]):\n",
    "    _, _, _, _, _, Ps, id_strs = batch     \n",
    "    batch = loaders[\"train\"].postprocess(batch, 'cpu')\n",
    "    imgs, meshes_gt, points_gt, normals_gt, voxels_gt = batch\n",
    "    #voxels_gt_r = rotateback(voxels_gt.cpu(), Ps.cpu())\n",
    "    voxels_gt = voxels_gt.float()  \n",
    "    \n",
    "    words = id_strs[0].split('-')\n",
    "    mesh_rcnn_predicted_voxels_dir = \"/home/alan/Desktop/meshrcnn_s/meshrcnn_s/datasets/shapenet/predictedVoxel\"\n",
    "    mesh_rcnn_predicted_voxels_dir = os.path.join(mesh_rcnn_predicted_voxels_dir, words[0], words[1], \"predictedVoxels.pt\")\n",
    "    mesh_rcnn_predicted_voxels = (torch.load(mesh_rcnn_predicted_voxels_dir).sigmoid()>0.7).float()\n",
    "    mesh_rcnn_predicted_voxels = rotateback(mesh_rcnn_predicted_voxels.cpu(), Ps.cpu()).float()\n",
    "    mesh_rcnn_predicted_voxels_input = mesh_rcnn_predicted_voxels[None, :, :, :, :, None]\n",
    "    print(\"voxels_gt.shape\")\n",
    "    print(voxels_gt.shape)\n",
    "    print(\"mesh_rcnn_predicted_voxels_input.shape\")\n",
    "    print(mesh_rcnn_predicted_voxels_input.shape)\n",
    "    result = model.predict(mesh_rcnn_predicted_voxels_input.cpu().detach().numpy())\n",
    "    result = (torch.from_numpy(np.squeeze(result))>0.7).float()\n",
    "    print(\"result.shape\")\n",
    "    print(result.shape)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "    rows=6, cols=3,\n",
    "    specs=[[{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],           \n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}]])    \n",
    "\n",
    "    # y_true = [[0, 1], [0, 0]]\n",
    "    # y_pred = [[-18.6, 0.51], [2.94, -12.8]]\n",
    "    # Using default 'auto'/'sum_over_batch_size' reduction type.\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    # print(bce(y_true, y_pred).numpy())    \n",
    "    \n",
    "    for index in range(0, 6):\n",
    "      \n",
    "        voxels_gt_np = voxels_gt[index].cpu().numpy()\n",
    "        X, Y, Z = np.mgrid[0:48:48j, 0:48:48j, 0:48:48j]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Volume(\n",
    "                x=X.flatten(),\n",
    "                y=Y.flatten(),\n",
    "                z=Z.flatten(),\n",
    "                value=voxels_gt_np.flatten(),\n",
    "                isomin=0,\n",
    "                isomax=1,\n",
    "                opacity=0.1, # needs to be small to see through all surfaces\n",
    "                surface_count=20, # needs to be a large number for good volume rendering\n",
    "                ),\n",
    "            row=index + 1,\n",
    "            col=1,\n",
    "        )   \n",
    "\n",
    "        print(np.histogram(voxels_gt_np.flatten()))\n",
    " \n",
    "        voxel_probs_np = mesh_rcnn_predicted_voxels[index].cpu().numpy()\n",
    "        X, Y, Z = np.mgrid[0:48:48j, 0:48:48j, 0:48:48j]\n",
    "\n",
    "        fig.add_trace(           \n",
    "            go.Volume(\n",
    "                x=X.flatten(),\n",
    "                y=Y.flatten(),\n",
    "                z=Z.flatten(),\n",
    "                value=voxel_probs_np.flatten(),\n",
    "                isomin=0,\n",
    "                isomax=1,\n",
    "                opacity=0.1, # needs to be small to see through all surfaces\n",
    "                surface_count=20, # needs to be a large number for good volume rendering\n",
    "            ),\n",
    "            row=index + 1,\n",
    "            col=2,        \n",
    "        )\n",
    "        \n",
    "        print(np.histogram(voxel_probs_np.flatten()))\n",
    "\n",
    "        X, Y, Z = np.mgrid[0:48:48j, 0:48:48j, 0:48:48j]        \n",
    "        fig.add_trace( \n",
    "            go.Volume(\n",
    "            x=X.flatten(),\n",
    "            y=Y.flatten(),\n",
    "            z=Z.flatten(),\n",
    "            value=result[index].numpy().flatten(),\n",
    "            isomin=0,\n",
    "            isomax=1,\n",
    "            opacity=0.1, # needs to be small to see through all surfaces\n",
    "            surface_count=20, # needs to be a large number for good volume rendering\n",
    "            ),\n",
    "            row=index + 1,\n",
    "            col=3,        \n",
    "        )\n",
    "        \n",
    "        print(np.histogram(result[index].flatten()))\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    #mesh_rcnn_predicted_voxels = rotateback(mesh_rcnn_predicted_voxels.cpu(), Ps.cpu()) \n",
    "    bce = tf.keras.losses.BinaryCrossentropy()    \n",
    "    print(\"index\")\n",
    "    print(index)\n",
    "    print(bce(voxels_gt[index].cpu().detach().numpy(), mesh_rcnn_predicted_voxels[index].cpu().detach().numpy()).numpy()) \n",
    "    print(bce(voxels_gt[index].cpu().detach().numpy(), result[index]).numpy())\n",
    "\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
