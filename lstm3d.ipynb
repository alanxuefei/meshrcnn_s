{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f9e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tools import train_net_shapenet\n",
    "\n",
    "class args:\n",
    "    config_file = \"configs/shapenet/voxmesh_R50.yaml\"\n",
    "    opts = \"\"\n",
    "    num_gpus = 0\n",
    "    data_dir = 'ShapeNetV1processed'\n",
    "    copy_data = False\n",
    "    no_color = True\n",
    "    \n",
    "cfg = train_net_shapenet.setup(args())\n",
    "loaders = train_net_shapenet.setup_loaders(cfg)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67786209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=(24, 48, 48, 48, 1)))\n",
    "model.add(layers.ConvLSTM3D(\n",
    "    filters=1,                           # number kernel\n",
    "    kernel_size=(9, 9, 9),                # shape kernel\n",
    "    padding=\"same\",                      # \"valid\" or \"same\"\n",
    "    strides=(1, 1, 1),                    # skip kernel \n",
    "    dilation_rate=(1, 1, 1),              # skip noron \n",
    "    return_sequences=True,               # output all noron if True\n",
    "    return_state=False,                   # True --> output + last state\n",
    "    go_backwards=False,                   # if go_backwards: --> inputs = reverse(inputs, 0)\n",
    "    stateful=False,                       # save state inloop --> but bachsizi input layer\n",
    "    activation=\"tanh\",                    # relu better \n",
    "    recurrent_activation=\"hard_sigmoid\",  # dont touch :D \n",
    "    # Layer weight customize -->\n",
    "    use_bias=False,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    recurrent_initializer=\"orthogonal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    unit_forget_bias=True,\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    # dropout --> not good\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    data_format='channels_last',\n",
    "))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.FalseNegatives()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/home/alan/Desktop/meshrcnn/log/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateback(voxels, P):\n",
    "    voxel_coords = []\n",
    "    for i, cur_voxels in enumerate(voxels):              \n",
    "        cur_voxel_coords = loaders[\"train\"].dataset._coordinates(cur_voxels, P[i].inverse())\n",
    "        voxel_coords.append(cur_voxel_coords) \n",
    "    voxel_coords = tuple(voxel_coords)\n",
    "    \n",
    "    voxels = []\n",
    "    for i, cur_voxel_coords in enumerate(voxel_coords):\n",
    "        cur_voxels = loaders[\"train\"].dataset._voxelize(cur_voxel_coords, P[0])\n",
    "        voxels.append(cur_voxels)\n",
    "    voxels = torch.stack(voxels, dim=0)\n",
    "    \n",
    "    return voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "x = torch.tensor(())\n",
    "y = torch.tensor(())\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "checkpoint_path = \"/home/alan/Desktop/lstm3dtest/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "missed = []\n",
    "\n",
    "for i, batch in enumerate(loaders[\"train\"]):\n",
    "\n",
    "    _, _, _, _, _, Ps, id_strs = batch    \n",
    "    batch = loaders[\"train\"].postprocess(batch, device)\n",
    "    imgs, meshes_gt, points_gt, normals_gt, voxels_gt = batch\n",
    "    \n",
    "    #voxels_gt = rotateback(voxels_gt.cpu(), Ps.cpu())     \n",
    "    voxels_gt = voxels_gt.float()  \n",
    "\n",
    "    words = id_strs[0].split('-')\n",
    "    output_dir = \"/home/alan/Desktop/meshrcnn_s/meshrcnn_s/datasets/shapenet/predictedVoxel\"\n",
    "    output_dir = os.path.join(output_dir, words[0], words[1], \"predictedVoxels.pt\")\n",
    "    if not exists(output_dir):\n",
    "        missed.append(output_dir)\n",
    "        continue\n",
    "    \n",
    "    voxel_scores = (torch.load(output_dir).sigmoid()>0.7).float()\n",
    "    assert(len(voxel_scores) == 24)\n",
    " \n",
    "    voxel_scores = rotateback(voxel_scores.cpu(), Ps.cpu())   \n",
    "\n",
    "    voxel_scores = voxel_scores[None, :, :, :, :, None]\n",
    "    \n",
    "    voxels_gt = voxels_gt[None, :, :, :, :, None]    \n",
    "\n",
    "    y = torch.cat((y, voxels_gt.cpu()), 0)\n",
    "    x = torch.cat((x, voxel_scores.cpu()), 0) \n",
    "\n",
    "    if len(x) == 8:\n",
    "        history = model.fit(x.detach().numpy(), y.detach().numpy(), \n",
    "                            batch_size=10,epochs=10000, verbose=1, validation_split=0.2, \n",
    "                            callbacks=[cp_callback, tensorboard_callback])       \n",
    "        x = torch.tensor(())\n",
    "        y = torch.tensor(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "checkpoint_path = \"/home/alan/Desktop/lstm3dtest/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)\n",
    " \n",
    "for i, batch in enumerate(loaders[\"train\"]):\n",
    "    _, _, _, _, _, Ps, id_strs = batch     \n",
    "    batch = loaders[\"train\"].postprocess(batch, 'cpu')\n",
    "    imgs, meshes_gt, points_gt, normals_gt, voxels_gt = batch\n",
    "    #voxels_gt_r = rotateback(voxels_gt.cpu(), Ps.cpu())\n",
    "    voxels_gt = voxels_gt.float()  \n",
    "    \n",
    "    words = id_strs[0].split('-')\n",
    "    mesh_rcnn_predicted_voxels_dir = \"/home/alan/Desktop/meshrcnn_s/meshrcnn_s/datasets/shapenet/predictedVoxel\"\n",
    "    mesh_rcnn_predicted_voxels_dir = os.path.join(mesh_rcnn_predicted_voxels_dir, words[0], words[1], \"predictedVoxels.pt\")\n",
    "    mesh_rcnn_predicted_voxels = (torch.load(mesh_rcnn_predicted_voxels_dir).sigmoid()>0.7).float()\n",
    "    mesh_rcnn_predicted_voxels = rotateback(mesh_rcnn_predicted_voxels.cpu(), Ps.cpu()).float()\n",
    "    mesh_rcnn_predicted_voxels_input = mesh_rcnn_predicted_voxels[None, :, :, :, :, None]\n",
    "    print(\"voxels_gt.shape\")\n",
    "    print(voxels_gt.shape)\n",
    "    print(\"mesh_rcnn_predicted_voxels_input.shape\")\n",
    "    print(mesh_rcnn_predicted_voxels_input.shape)\n",
    "    result = model.predict(mesh_rcnn_predicted_voxels_input.cpu().detach().numpy())\n",
    "    #result = (torch.from_numpy(np.squeeze(result))>0.7).float()\n",
    "    result = (torch.from_numpy(np.squeeze(result))).float()\n",
    "    print(\"result.shape\")\n",
    "    print(result.shape)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "    rows=6, cols=3,\n",
    "    specs=[[{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],\n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}],           \n",
    "           [{'type': 'volume'}, {'type': 'volume'}, {'type': 'volume'}]])    \n",
    "\n",
    "    # y_true = [[0, 1], [0, 0]]\n",
    "    # y_pred = [[-18.6, 0.51], [2.94, -12.8]]\n",
    "    # Using default 'auto'/'sum_over_batch_size' reduction type.\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    # print(bce(y_true, y_pred).numpy())    \n",
    "    \n",
    "    for index in range(0, 6):\n",
    "      \n",
    "        voxels_gt_np = voxels_gt[index].cpu().numpy()\n",
    "        X, Y, Z = np.mgrid[0:48:48j, 0:48:48j, 0:48:48j]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Volume(\n",
    "                x=X.flatten(),\n",
    "                y=Y.flatten(),\n",
    "                z=Z.flatten(),\n",
    "                value=voxels_gt_np.flatten(),\n",
    "                isomin=0,\n",
    "                isomax=1,\n",
    "                opacity=0.1, # needs to be small to see through all surfaces\n",
    "                surface_count=20, # needs to be a large number for good volume rendering\n",
    "                ),\n",
    "            row=index + 1,\n",
    "            col=1,\n",
    "        )   \n",
    "\n",
    "        print(np.histogram(voxels_gt_np.flatten()))\n",
    " \n",
    "        voxel_probs_np = mesh_rcnn_predicted_voxels[index].cpu().numpy()\n",
    "        X, Y, Z = np.mgrid[0:48:48j, 0:48:48j, 0:48:48j]\n",
    "\n",
    "        fig.add_trace(           \n",
    "            go.Volume(\n",
    "                x=X.flatten(),\n",
    "                y=Y.flatten(),\n",
    "                z=Z.flatten(),\n",
    "                value=voxel_probs_np.flatten(),\n",
    "                isomin=0,\n",
    "                isomax=1,\n",
    "                opacity=0.1, # needs to be small to see through all surfaces\n",
    "                surface_count=20, # needs to be a large number for good volume rendering\n",
    "            ),\n",
    "            row=index + 1,\n",
    "            col=2,        \n",
    "        )\n",
    "        \n",
    "        print(np.histogram(voxel_probs_np.flatten()))\n",
    "\n",
    "        X, Y, Z = np.mgrid[0:48:48j, 0:48:48j, 0:48:48j]        \n",
    "        fig.add_trace( \n",
    "            go.Volume(\n",
    "            x=X.flatten(),\n",
    "            y=Y.flatten(),\n",
    "            z=Z.flatten(),\n",
    "            value=result[index].numpy().flatten(),\n",
    "            isomin=0,\n",
    "            isomax=1,\n",
    "            opacity=0.1, # needs to be small to see through all surfaces\n",
    "            surface_count=20, # needs to be a large number for good volume rendering\n",
    "            ),\n",
    "            row=index + 1,\n",
    "            col=3,        \n",
    "        )\n",
    "        \n",
    "        print(np.histogram(result[index].flatten()))\n",
    "    \n",
    "    #fig.show()\n",
    "    \n",
    "    #mesh_rcnn_predicted_voxels = rotateback(mesh_rcnn_predicted_voxels.cpu(), Ps.cpu()) \n",
    "    bce = tf.keras.losses.BinaryCrossentropy()    \n",
    "    print(\"index\")\n",
    "    print(index)\n",
    "    print(bce(voxels_gt[index].cpu().detach().numpy(), mesh_rcnn_predicted_voxels[index].cpu().detach().numpy()).numpy()) \n",
    "    print(bce(voxels_gt[index].cpu().detach().numpy(), result[index]).numpy())\n",
    "\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92df920",
   "metadata": {},
   "outputs": [],
   "source": [
    "2c96b939342fcda4360c528c0fc0d777\n",
    "2c981b96364b1baa21a66e8dfcce514a\n",
    "2ca59da312d06381b927782fc69a1fbb\n",
    "\n",
    "# European Conference on Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d07dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ConvLSTM3D\n",
    "0.0037270044\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87d26e03",
   "metadata": {},
   "source": [
    "International Journal of Computer Vision volume"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
